# plot_component_sizes.py

A comprehensive visualization tool for analyzing component-size distributions from segmentation results. This script processes `*_components.csv` files to generate various plots showing coverage curves, weight distributions, and family-based comparisons.

## Overview

The script analyzes component CSV files (generated by segmentation algorithms) and creates visualizations grouped by dataset families. It supports filtering based on segmentation performance metrics and provides both combined overview plots and detailed per-family breakdowns.

## Features


## Usage Examples

### Basic Usage

```bash
# Scan default directory for component CSV files
python scripts/benchmarks/plot_component_sizes.py \
  --root scripts/benchmarks/out/components \
  --outdir scripts/benchmarks/out/component_size_plots
```

### Advanced Usage with Filtering

```bash
# Process specific files with performance filtering
python scripts/benchmarks/plot_component_sizes.py \
  --files file1.csv file2.csv \
  --outdir plots/ \
  --title "Segmentation Analysis" \
  --filter-config configs/filters.json \
  --results-csv segmentation_results.csv \
  --exclude-families family1 family2 \
  --fontsize 8.0 \
  --seed 42
```

### Meta File Integration

```bash
# Use custom meta.csv for family mapping
python scripts/benchmarks/plot_component_sizes.py \
  --root components/ \
  --meta benchmarks/custom/meta.csv \
  --outdir analysis_plots/
```

## Command Line Arguments

| Argument | Type | Default | Description |
|----------|------|---------|-------------|
| `--root` | Path | `scripts/benchmarks/out/components` | Root directory to scan for `*_components.csv` files (recursive) |
| `--files` | Path[] | None | Specific CSV files to process (overrides `--root`) |
| `--outdir` | Path | `scripts/benchmarks/out/component_size_plots` | Output directory for generated plots |
| `--title` | str | None | Optional title prefix for all plots |
| `--fontsize` | float | 7.0 | Font size for plot titles, axis labels, ticks, and legends (points) |
| `--seed` | int | 0 | Random seed for deterministic family style assignment (change to reshuffle colors/markers/linestyles) |
| `--meta` | Path | `benchmarks/sc2024/meta.csv` | Path to meta.csv with hash,family columns |
| `--results-csv` | Path | `scripts/benchmarks/out/segmentation_results.csv` | Segmentation results for filtering |
| `--filter-config` | Path | `scripts/benchmarks/configs/segmentation_results_filters.example.json` | JSON filter configuration |
| `--exclude-families` | str[] | None | Family names to exclude from plots |

## Input File Formats

### Component CSV Files (`*_components.csv`)

Required columns:
- `size`: Integer component size (number of nodes)

Optional columns:
- `min_internal_weight`: Float minimum internal edge weight for weight analysis

Example:
```csv
size,min_internal_weight
150,0.85
89,0.72
45,0.91
...
```

### Meta CSV File (`meta.csv`)

Required columns:
- `hash`: File hash identifier (extracted from filenames)
- `family`: Dataset family name

Example:
```csv
hash,family,other_metadata
94dd280b1562ee7dae44b303b8fed233,sat_competition,extra_info
a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6,industrial,more_data
...
```

### Segmentation Results CSV (`segmentation_results.csv`)

Contains performance metrics for filtering. Common columns:
- `file`: Filename (hash will be extracted)
- `comps`: Number of components
- `vars`: Number of variables
- `total_sec`: Total runtime
- `parse_sec`: Parsing time
- Any other numeric metrics

### Filter Configuration JSON

Defines min/max thresholds for filtering segmentation results:

```json
{
  "min": {
    "comps": 2,
    "vars": 100,
    "total_sec": 0.1
  },
  "max": {
    "total_sec": 3600,
    "memory_mb": 8192
  }
}
```

## Output Files

### Main Directory (`--outdir`)

- **`combined_topn_coverage.png`**: Overlay plot showing percent coverage by top-n components for all families
- **`combined_topn_coverage_legend.png`**: Legend image for the combined coverage plot
- **`combined_topn_avg_min_internal_weight.png`**: Combined average weight curves by family
- **`combined_topn_avg_min_internal_weight_legend.png`**: Legend image for the combined weight plot
- **`combined_size_id_map.csv`**: Mapping file translating compact IDs to full metadata

### Family Subdirectory (`--outdir/families/`)

For each family with ≥3 instances:
- **`topn_coverage_<family>.png`**: Coverage curves for individual files in the family
- **`topn_coverage_<family>_legend.png`**: Legend image for the family coverage plot
- **`topn_avg_min_internal_weight_<family>.png`**: Weight curves for individual files in the family
- **`topn_avg_min_internal_weight_<family>_legend.png`**: Legend image for the family weight plot

### ID Mapping CSV Columns

| Column | Description |
|--------|-------------|
| `id` | 3-character base62 identifier (a-zA-Z0-9) |
| `label` | Human-readable label with tau/k parameters |
| `file` | Source file path (relative to `--root` when applicable) |
| `family` | Dataset family name |
| `n_sizes` | Number of components in the file |

## Algorithm Details

### Family Assignment
1. Extract hash from filename (text before first '-')
2. Look up family in meta.csv using hash
3. Assign "unknown" family if not found or invalid

### Filtering Process
1. Load segmentation results CSV and build hash-based index
2. For each component CSV, extract hash and find corresponding results
3. Apply min/max thresholds from filter configuration
4. Skip files that don't meet all criteria

### Coverage Calculation
1. Sort component sizes in descending order
2. Compute cumulative sum of sizes
3. Calculate percentage of total covered by top-n components
4. Plot n (log scale) vs coverage percentage

### Weight Analysis
1. Sort components by size (descending)
2. Compute running average of minimum internal weights
3. Handle missing/infinite values gracefully
4. Plot on log-log scale

### Legend Management
- Generate stable 3-character base62 IDs for compact legends
- Support up to 238,328 unique identifiers (62³)
- Maintain consistent ID assignment across runs

## Family Requirements

- Families need ≥3 instances to appear in plots
- Excluded families are filtered out before plotting
- Family colors and styles are automatically assigned
- Unknown/invalid families are grouped as "unknown"

## Dependencies

Install the required environment using conda:

```bash
conda env create -f scripts/benchmarks/environment.yml
conda activate thesis-bench
```

Required packages:
- `python>=3.9,<3.13`
- `pandas` - Data manipulation and CSV processing
- `numpy` - Numerical computations and array operations  
- `matplotlib` - Core plotting functionality
- `seaborn` - Statistical visualization and styling
- `networkx` - (Indirect dependency for some analysis)

## Error Handling

The script includes robust error handling for:
- Missing or malformed CSV files
- Invalid numeric data in components or results
- Missing family metadata
- Filter configuration errors
- File system permissions issues

Warnings and errors are printed to console with descriptive messages.

## Performance Considerations

- Files with ≤2 components are automatically skipped
- Memory usage scales with total number of components across all files
- Large datasets may benefit from filtering to reduce processing time
- Plot generation time increases with number of families and files per family

## Integration

This script is part of the thesis benchmarking pipeline and integrates with:
- `segmentation_eval_runner.py` - Generates component CSV files
- `plot_segmentation_results.py` - Complementary performance analysis
- `family_map_utils.py` - Shared family mapping utilities
- `plot_styles.py` - Consistent visual styling across tools
